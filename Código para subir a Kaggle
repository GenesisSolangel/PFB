#!pip install supabase pandas scikit-learn tensorflow plotly (esto hay qye instalarlo para hacer la conexión con supabase y plotly)


import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
from sklearn.preprocessing import MinMaxScaler
import plotly.express as px
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, LSTM, Dense
from supabase import create_client, Client

SUPABASE_URL = "https://yhkeqdysmjirdrfrmvjd.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inloa2VxZHlzbWppcmRyZnJtdmpkIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDkwMTA0NDQsImV4cCI6MjA2NDU4NjQ0NH0.Hn0G1jCxDuhzb4AnZyJAC3KGQGIq5Cxn8wgEc-_1fLo"
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# DESCARGA DE DATOS (aqui puse solo los 90 días para probar y que no tardadra pero hay que modificar a los 10 ultimos años)

def get_demanda_data():
    end = datetime.now(timezone.utc)
    start = end - timedelta(days=90)
    response = (
        supabase.table("demanda")
        .select("datetime,value")
        .gte("datetime", start.isoformat())
        .lte("datetime", end.isoformat())
        .execute()
    )
    df = pd.DataFrame(response.data)
    df['datetime'] = pd.to_datetime(df['datetime'])
    df.sort_values('datetime', inplace=True)
    return df




# PREPROCESAMIENTO PARA RNN

def preprocess_for_rnn(df, window_size=24):
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['value']])
    X, y = [], []
    for i in range(len(scaled) - window_size):
        X.append(scaled[i:i+window_size])
        y.append(scaled[i+window_size])
    X = np.array(X).reshape(-1, window_size, 1)
    y = np.array(y)
    return X, y, scaler




# ENTRENAMIENTO DEL MODELO

def train_model(X, y, model_type='RNN', loss_fn='mse'):
    model = Sequential()
    if model_type == 'RNN':
        model.add(SimpleRNN(50, activation='tanh', input_shape=(X.shape[1], 1)))
    elif model_type == 'LSTM':
        model.add(LSTM(50, activation='tanh', input_shape=(X.shape[1], 1)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss=loss_fn)
    history = model.fit(X, y, epochs=10, batch_size=32, verbose=1)
    return model, history



# ONE-STEP PREDICTION

def one_step_prediction(model, X, scaler):
    pred = model.predict(X)
    return scaler.inverse_transform(pred)



# MULTI-STEP PREDICTION

def multi_step_prediction(model, initial_sequence, steps, scaler):
    sequence = initial_sequence.copy()
    predictions = []
    for _ in range(steps):
        pred = model.predict(sequence.reshape(1, -1, 1))
        predictions.append(pred[0, 0])
        sequence = np.append(sequence[1:], pred[0, 0]).reshape(-1, 1)
    return scaler.inverse_transform(np.array(predictions).reshape(-1, 1))


# EJECUCIÓN PRINCIPAL

df = get_demanda_data()
print("Datos obtenidos:", df.shape)

window_size = 24
X, y, scaler = preprocess_for_rnn(df, window_size)
print("Datos preprocesados para RNN:", X.shape)

model_type = 'LSTM'  # Cambia a 'RNN' si deseas
loss_fn = 'mse'

model, history = train_model(X, y, model_type, loss_fn)

# Gráfico de pérdida
fig_loss = px.line(
    y=history.history[loss_fn],
    labels={"x": "Época", "y": f"{loss_fn.upper()}"},
    title="Pérdida durante el entrenamiento"
)
fig_loss.show()

# One-step
y_pred = one_step_prediction(model, X, scaler)
y_true = scaler.inverse_transform(y.reshape(-1, 1))

result_df = pd.DataFrame({
    "datetime": df['datetime'][window_size:].values,
    "Real": y_true.flatten(),
    "Predicción": y_pred.flatten()
})
px.line(result_df, x="datetime", y=["Real", "Predicción"], title="Predicción One-Step").show()

# Multi-step
steps = 24
latest_seq = X[-1].reshape(-1, 1)
multistep = multi_step_prediction(model, latest_seq, steps, scaler)

future_dates = pd.date_range(df["datetime"].iloc[-1] + timedelta(hours=1), periods=steps, freq='H')
future_df = pd.DataFrame({"datetime": future_dates, "Predicción": multistep.flatten()})
px.line(future_df, x="datetime", y="Predicción", title="Predicción Multiple-Step").show()
